{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83063c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "\n",
      "show_id            0\n",
      "type               0\n",
      "title              0\n",
      "director        2634\n",
      "cast             825\n",
      "country          831\n",
      "date_added        10\n",
      "release_year       0\n",
      "rating             4\n",
      "duration           3\n",
      "listed_in          0\n",
      "description        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after handling:\n",
      "\n",
      "show_id         0\n",
      "type            0\n",
      "title           0\n",
      "director        0\n",
      "cast            0\n",
      "country         0\n",
      "date_added      0\n",
      "release_year    0\n",
      "rating          0\n",
      "duration        0\n",
      "listed_in       0\n",
      "description     0\n",
      "dtype: int64\n",
      "Number of Duplicates before handling:\n",
      "0\n",
      "Number of Duplicates after handling:\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samragya\\AppData\\Local\\Temp\\ipykernel_24020\\986868408.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset \n",
    "df = pd.read_csv(\"netflix_titles.csv\", encoding='utf-8')  \n",
    "\n",
    "# Identify and handle missing values\n",
    "print(\"Missing values before handling:\\n\") \n",
    "print(df.isnull().sum())\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"\\nMissing values after handling:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"Number of Duplicates before handling:\")\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"Number of Duplicates after handling:\")\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Standardize text values like country\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].str.strip().str.lower()\n",
    "\n",
    "#  Convert date columns to datetime (adjust column names as needed)\n",
    "date_cols = ['date_added',]  # replace with your actual date columns\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
    "        \n",
    "df['release_year'] = pd.to_datetime(df['release_year']).dt.normalize()\n",
    "\n",
    "\n",
    "# Rename column headers to be clean and uniform\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Check and fix data types (example: age as int)\n",
    "if 'age' in df.columns:\n",
    "    df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"Final_Data.csv\", index=False)\n",
    "\n",
    "# Convert into excel file\n",
    "csv_file = \"Final_Data.csv\"  \n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "excel_file = \"Final_Data.xlsx\" \n",
    "df.to_excel(excel_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
